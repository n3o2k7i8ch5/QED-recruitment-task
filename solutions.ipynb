{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "from datetime import datetime\n",
    "from math import copysign\n",
    "from numpy.core.defchararray import isnumeric\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Module, Sequential, Linear, Dropout, LeakyReLU, Sigmoid, LSTM\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:15:19.670656732Z",
     "start_time": "2023-11-17T16:15:15.225918572Z"
    }
   },
   "id": "36d82bde1d460540"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preperation - common"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7400ab9940ccd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Large value span differences do not work well with neural networks.\n",
    "Take the `column_name` column with numeric values in the `df` dataframe\n",
    "and replace its values with their base 2 logarithm.\n",
    "\n",
    "1 is added to the number in order to prevent large negative values when \n",
    "taking the log of 0 < x << 1.\n",
    "\"\"\"\n",
    "logarithimize = lambda x: copysign(1, x) * log(abs(x) + 1, 2)\n",
    "\n",
    "def encoded_ip_to_binary(ip: str) -> list[bool]:\n",
    "    \"\"\"\n",
    "    Transform encoded IPs e.g. 'MW.YB.50.64' into a unique, repeatable list of `0`s and `1`s.\n",
    "    Each segment divided by a '.' will be transformed to an integer, which will be later encoded as a \n",
    "    10 bit number.\n",
    "    If a segment is numeric (e.g. '50'), it will be parsed immediately to an int.\n",
    "    If a segment is non-numeric (e.g. 'MW') it will be converted to a number by a following function:\n",
    "    `f(s) = 256 + ordinal(s[0]) * ordinal(s[1])`, where `ordinal(c)` assigns `0` to `a`, `1` to `b` etc.\n",
    "    256 is added to avoid collisions with numerical segments.\n",
    "    \n",
    "    All segments are then transformed into 10 bit binary numbers.\n",
    "    \n",
    "    Since there are 26 letter available in the alfabet, the maximum value of the encoded segment is:\n",
    "    256 + 26*26 = 932, which means 10 bits are needed to encode segment, a total of 40 bits for each IP address.\n",
    "    \"\"\"\n",
    "    ordinal = lambda c: ord(c) - ord('A')\n",
    "    \n",
    "    if type(ip) is not str:\n",
    "        return [False]*40\n",
    "    \n",
    "    result = []\n",
    "    for part in ip.split('.'):\n",
    "        try:\n",
    "            numeric = int(part) if isnumeric(part) else 256 + ordinal(part[0])*ordinal(part[1])\n",
    "        except IndexError:\n",
    "            # It might happen that an invalid IP is passed, e.g. 'RZ..202.16'\n",
    "            numeric = 1023\n",
    "        binary_str = bin(numeric).replace('0b', '').rjust(10, '0')\n",
    "        binary_arr = [b=='1' for b in binary_str]\n",
    "        \n",
    "        result.extend(binary_arr)\n",
    "\n",
    "    return result\n",
    "\n",
    "def port_to_binary(port: str) -> list[bool]:\n",
    "    \"\"\"\n",
    "    Convert port from int to a binary number.\n",
    "    The maximum socket (port) number is 65535 - 16 bits are needed to encode all.\n",
    "    \"\"\"\n",
    "    if type(port) is not str:\n",
    "        return [False]*16\n",
    "    \n",
    "    binary = bin(int(port)).replace('0b', '').rjust(16, '0')\n",
    "    return [b=='1' for b in binary]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:15:19.691073485Z",
     "start_time": "2023-11-17T16:15:19.671227715Z"
    }
   },
   "id": "33cc99d3ad4d8ecc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preperation \n",
    "\n",
    "Since only the `cybersecurity_training.csv` dataset is labeled, it will be split into two parts:\n",
    "\\- training subset\n",
    "\\- test subset (in order to evaluate the proposed algorithm)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f796015960ac9f8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(present_alert_ids)=59427\n"
     ]
    },
    {
     "data": {
      "text/plain": "  alert_ids categoryname            ip ipcategory_name ipcategory_scope  \\\n0       Nhq       Attack   YT.LB.32.21        INTERNET         Internet   \n1       XZt      Exploit  192.SL.UK.94        PRIV-192  Private network   \n2       bBz       Attack   YT.LB.38.21        INTERNET         Internet   \n3       ZNr       Attack   JX.NY.13.20        INTERNET         Internet   \n4       poV       Attack   YT.LB.32.21        INTERNET         Internet   \n\n   parent_category grandparent_category  overallseverity  timestamp_dist  \\\n0                7                    A                3           65684   \n1                1                    A                5         1188030   \n2                7                    A                4           43716   \n3                7                    A                4               0   \n4                7                    A                4            2401   \n\n   start_hour  ...  thrcnt_week  thrcnt_day p6  p9  p5m  p5w  p5d  p8m  p8w  \\\n0           8  ...         4160         675  1   0    2    1    1    1    1   \n1           1  ...            9           2  4  12    3    2    2    2    1   \n2          14  ...         3788         628  1   0    2    2    1    2    2   \n3          20  ...          565          96  0   0    2    2    2    2    2   \n4          14  ...         2790         632  1   0    1    1    1    1    1   \n\n   p8d  \n0    1  \n1    1  \n2    1  \n3    2  \n4    1  \n\n[5 rows x 61 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alert_ids</th>\n      <th>categoryname</th>\n      <th>ip</th>\n      <th>ipcategory_name</th>\n      <th>ipcategory_scope</th>\n      <th>parent_category</th>\n      <th>grandparent_category</th>\n      <th>overallseverity</th>\n      <th>timestamp_dist</th>\n      <th>start_hour</th>\n      <th>...</th>\n      <th>thrcnt_week</th>\n      <th>thrcnt_day</th>\n      <th>p6</th>\n      <th>p9</th>\n      <th>p5m</th>\n      <th>p5w</th>\n      <th>p5d</th>\n      <th>p8m</th>\n      <th>p8w</th>\n      <th>p8d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Nhq</td>\n      <td>Attack</td>\n      <td>YT.LB.32.21</td>\n      <td>INTERNET</td>\n      <td>Internet</td>\n      <td>7</td>\n      <td>A</td>\n      <td>3</td>\n      <td>65684</td>\n      <td>8</td>\n      <td>...</td>\n      <td>4160</td>\n      <td>675</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XZt</td>\n      <td>Exploit</td>\n      <td>192.SL.UK.94</td>\n      <td>PRIV-192</td>\n      <td>Private network</td>\n      <td>1</td>\n      <td>A</td>\n      <td>5</td>\n      <td>1188030</td>\n      <td>1</td>\n      <td>...</td>\n      <td>9</td>\n      <td>2</td>\n      <td>4</td>\n      <td>12</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bBz</td>\n      <td>Attack</td>\n      <td>YT.LB.38.21</td>\n      <td>INTERNET</td>\n      <td>Internet</td>\n      <td>7</td>\n      <td>A</td>\n      <td>4</td>\n      <td>43716</td>\n      <td>14</td>\n      <td>...</td>\n      <td>3788</td>\n      <td>628</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ZNr</td>\n      <td>Attack</td>\n      <td>JX.NY.13.20</td>\n      <td>INTERNET</td>\n      <td>Internet</td>\n      <td>7</td>\n      <td>A</td>\n      <td>4</td>\n      <td>0</td>\n      <td>20</td>\n      <td>...</td>\n      <td>565</td>\n      <td>96</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>poV</td>\n      <td>Attack</td>\n      <td>YT.LB.32.21</td>\n      <td>INTERNET</td>\n      <td>Internet</td>\n      <td>7</td>\n      <td>A</td>\n      <td>4</td>\n      <td>2401</td>\n      <td>14</td>\n      <td>...</td>\n      <td>2790</td>\n      <td>632</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 61 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "cybersecurity_training = pd.read_csv('data/cybersecurity_training.csv', sep='|')\n",
    "cybersecurity_test = pd.read_csv('data/cybersecurity_test.csv', sep='|', usecols=['alert_ids'])\n",
    "\n",
    "y = cybersecurity_training.pop('notified')\n",
    "X = cybersecurity_training\n",
    "\n",
    "train_alert_ids = set(X['alert_ids'].unique())\n",
    "test_alert_ids = set(cybersecurity_test['alert_ids'].unique())\n",
    "\n",
    "present_alert_ids = list(train_alert_ids.union(test_alert_ids))\n",
    "\n",
    "def alert_id_to_int(alert_id: int):\n",
    "    try:\n",
    "        return present_alert_ids.index(alert_id)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "print(f'{len(present_alert_ids)=}')\n",
    "\n",
    "# Encrypted client ids will not be used.\n",
    "X.pop('client_code')\n",
    "\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:15:20.095912820Z",
     "start_time": "2023-11-17T16:15:19.685654402Z"
    }
   },
   "id": "5af6f2fe9d9edd3c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   alert_ids  timestamp_dist  start_hour  start_minute  start_second  \\\n0        839       16.003276           8            14            34   \n1      24700       20.180141           1             0             2   \n2      25316       15.415907          14            44             5   \n3      51034        0.000000          20            33            40   \n4       7344       11.230020          14            36            11   \n\n   correlatedcount  srcip_cd  dstip_cd  srcport_cd  dstport_cd  ...  p8w$2.0  \\\n0         6.129283  5.247928  1.000000    6.087463    1.584963  ...    False   \n1        12.372593  1.000000  5.554589   12.212800    4.321928  ...    False   \n2         8.438792  8.204571  1.000000    8.430453    1.584963  ...     True   \n3         1.000000  0.000000  0.000000    0.000000    0.000000  ...     True   \n4         1.000000  1.000000  1.000000    1.000000    1.000000  ...    False   \n\n   p8w$3.0  p8w$4.0  p8w$5.0  p8w$nan  p8d$1.0  p8d$2.0  p8d$3.0  p8d$4.0  \\\n0    False    False    False    False     True    False    False    False   \n1    False    False    False    False     True    False    False    False   \n2    False    False    False    False     True    False    False    False   \n3    False    False    False    False    False     True    False    False   \n4    False    False    False    False     True    False    False    False   \n\n   p8d$nan  \n0    False  \n1    False  \n2    False  \n3    False  \n4    False  \n\n[5 rows x 380 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alert_ids</th>\n      <th>timestamp_dist</th>\n      <th>start_hour</th>\n      <th>start_minute</th>\n      <th>start_second</th>\n      <th>correlatedcount</th>\n      <th>srcip_cd</th>\n      <th>dstip_cd</th>\n      <th>srcport_cd</th>\n      <th>dstport_cd</th>\n      <th>...</th>\n      <th>p8w$2.0</th>\n      <th>p8w$3.0</th>\n      <th>p8w$4.0</th>\n      <th>p8w$5.0</th>\n      <th>p8w$nan</th>\n      <th>p8d$1.0</th>\n      <th>p8d$2.0</th>\n      <th>p8d$3.0</th>\n      <th>p8d$4.0</th>\n      <th>p8d$nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>839</td>\n      <td>16.003276</td>\n      <td>8</td>\n      <td>14</td>\n      <td>34</td>\n      <td>6.129283</td>\n      <td>5.247928</td>\n      <td>1.000000</td>\n      <td>6.087463</td>\n      <td>1.584963</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24700</td>\n      <td>20.180141</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>12.372593</td>\n      <td>1.000000</td>\n      <td>5.554589</td>\n      <td>12.212800</td>\n      <td>4.321928</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25316</td>\n      <td>15.415907</td>\n      <td>14</td>\n      <td>44</td>\n      <td>5</td>\n      <td>8.438792</td>\n      <td>8.204571</td>\n      <td>1.000000</td>\n      <td>8.430453</td>\n      <td>1.584963</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51034</td>\n      <td>0.000000</td>\n      <td>20</td>\n      <td>33</td>\n      <td>40</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7344</td>\n      <td>11.230020</td>\n      <td>14</td>\n      <td>36</td>\n      <td>11</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 380 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS_TO_LOGARITHMIZE = [\n",
    "    'timestamp_dist', 'correlatedcount', 'srcip_cd', 'dstip_cd', 'srcport_cd', 'dstport_cd', 'thrcnt_month', 'thrcnt_week', 'thrcnt_day', 'alerttype_cd', 'direction_cd', 'eventname_cd', 'severity_cd', 'reportingdevice_cd', 'devicetype_cd', 'devicevendor_cd', 'domain_cd', 'protocol_cd', 'username_cd', 'srcipcategory_cd', 'dstipcategory_cd'\n",
    "]\n",
    "\n",
    "COLUMNS_TO_ONEHOTIZE = [\n",
    "    'categoryname', 'ipcategory_name', 'ipcategory_scope', 'parent_category', 'grandparent_category', 'overallseverity', 'weekday', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'score', 'isiptrusted', 'untrustscore', 'flowscore', 'trustscore', 'enforcementscore', 'dstipcategory_dominate', 'srcipcategory_dominate', 'dstportcategory_dominate', 'srcportcategory_dominate', 'p6', 'p9', 'p5m', 'p5w', 'p5d', 'p8m', 'p8w', 'p8d'\n",
    "]\n",
    "\n",
    "# Encode alert_ids to int (str values are invalid in torch tensors)\n",
    "X['alert_ids'] = X['alert_ids'].apply(alert_id_to_int)\n",
    "\n",
    "# Transform IPs into binary\n",
    "X_ip_bin = pd.DataFrame(\n",
    "    data=[encoded_ip_to_binary(ip) for ip in X.pop('ip')],\n",
    "    columns=[f'ip{i}' for i in range(40)],\n",
    "    index=X.index\n",
    ")\n",
    "X = pd.concat([X, X_ip_bin], axis=1)\n",
    "\n",
    "# Logarithmize columns\n",
    "for column_name in COLUMNS_TO_LOGARITHMIZE:\n",
    "    X[column_name] = X[column_name].apply(logarithimize)\n",
    "\n",
    "# Encode columns to one-hot\n",
    "X = pd.get_dummies(X, columns=COLUMNS_TO_ONEHOTIZE, prefix_sep='$', dummy_na=True, dtype=bool)\n",
    "\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:15:53.349361976Z",
     "start_time": "2023-11-17T16:15:20.084482772Z"
    }
   },
   "id": "908c14065e1e17a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preperation - localized alerts (log stack)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74e72ad056d85517"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed localized alerts found at dumps/localized_alerts_data_dump.pkl. Loading dump.\n"
     ]
    },
    {
     "data": {
      "text/plain": "        direction  alerttime  severity  count  domain  username  signature  \\\n5483893         5        0.0         1    2.0       0         1          1   \n\n         protocol$dns  protocol$http  protocol$https  ...  dstport6  dstport7  \\\n5483893         False          False           False  ...     False     False   \n\n         dstport8  dstport9  dstport10  dstport11  dstport12  dstport13  \\\n5483893     False     False      False      False      False      False   \n\n         dstport14  dstport15  \n5483893      False      False  \n\n[1 rows x 282 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>direction</th>\n      <th>alerttime</th>\n      <th>severity</th>\n      <th>count</th>\n      <th>domain</th>\n      <th>username</th>\n      <th>signature</th>\n      <th>protocol$dns</th>\n      <th>protocol$http</th>\n      <th>protocol$https</th>\n      <th>...</th>\n      <th>dstport6</th>\n      <th>dstport7</th>\n      <th>dstport8</th>\n      <th>dstport9</th>\n      <th>dstport10</th>\n      <th>dstport11</th>\n      <th>dstport12</th>\n      <th>dstport13</th>\n      <th>dstport14</th>\n      <th>dstport15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5483893</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 282 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCALIZED_ALERTS_PATH = 'data/localized_alerts_data.csv'\n",
    "DUMPS_DIR = 'dumps'\n",
    "LOCALIZED_ALERTS_DUMP_PATH = f'{DUMPS_DIR}/localized_alerts_data_dump.pkl'\n",
    "\n",
    "localized_alerts_by_alert_id: dict[str, pd.DataFrame]\n",
    "\n",
    "if os.path.exists(LOCALIZED_ALERTS_DUMP_PATH):\n",
    "    print(f'Processed localized alerts found at {LOCALIZED_ALERTS_DUMP_PATH}. Loading dump.')\n",
    "    with open(LOCALIZED_ALERTS_DUMP_PATH, 'rb') as handle:\n",
    "        localized_alerts_by_alert_id = pickle.load(handle)\n",
    "        \n",
    "else:\n",
    "    print(f'Processed localized alerts dump not found. Preprocessing data...')\n",
    "    localized_alerts = pd.read_csv(\n",
    "        LOCALIZED_ALERTS_PATH, sep='|', \n",
    "        dtype={\n",
    "            'alert_ids': str, 'alerttype': str, 'devicetype': str, 'reportingdevice_code': str, 'devicevendor_code': str, 'srcip': str, 'dstip': str, 'srcipcategory': str, 'dstipcategory': str, 'srcport': str, 'dstport': str, 'srcportcategory': str, 'dstportcategory': str, 'direction': str, 'alerttime': int, 'severity': int, 'count': int, 'domain': int, 'protocol': str, 'username': int, 'signature': int\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Drop unused\n",
    "    localized_alerts.drop(columns=['reportingdevice_code'], inplace=True)\n",
    "    \n",
    "    COLUMNS_TO_LOGARITHMIZE = [\n",
    "        'alerttime', 'count'\n",
    "    ]\n",
    "    COLUMNS_TO_ONEHOTIZE = [\n",
    "        'protocol', 'alerttype', 'devicetype', 'devicevendor_code', 'srcipcategory', 'dstipcategory', 'srcportcategory', 'dstportcategory'\n",
    "    ]\n",
    "    COLUMNS_TO_IP_BINARY = [\n",
    "        'srcip', 'dstip'\n",
    "    ]\n",
    "    COLUMNS_TO_PORT_BINARY = [\n",
    "        'srcport', 'dstport'\n",
    "    ]\n",
    "    \n",
    "    def simplify_web_protocol(protocol: str):\n",
    "        if type(protocol) is not str:\n",
    "            return 'other'\n",
    "\n",
    "        if protocol == '-':\n",
    "            return 'other'\n",
    "    \n",
    "        protocol = protocol.lower()\n",
    "    \n",
    "        if 'udp' in protocol:\n",
    "            return 'udp'\n",
    "        elif 'tcp' in protocol:\n",
    "            return 'tcp'\n",
    "        elif 'https' in protocol:\n",
    "            return 'https'\n",
    "        elif 'http' in protocol:\n",
    "            return 'http'\n",
    "        elif 'dns' in protocol:\n",
    "            return 'dns'\n",
    "\n",
    "        return 'other'\n",
    "\n",
    "    localized_alerts['protocol'] = localized_alerts['protocol'].apply(simplify_web_protocol)\n",
    "    \n",
    "    for column_name in COLUMNS_TO_LOGARITHMIZE:\n",
    "        localized_alerts[column_name] = localized_alerts[column_name].apply(logarithimize)\n",
    "    print('[1/6] Logarithmizing completed.')\n",
    "\n",
    "    localized_alerts = pd.get_dummies(localized_alerts, columns=COLUMNS_TO_ONEHOTIZE, prefix_sep='$', dummy_na=True, dtype=bool)\n",
    "    print('[2/6] Onehot completed.')\n",
    "\n",
    "    ip_bin_dfs = []\n",
    "    for i, column_name in enumerate(COLUMNS_TO_IP_BINARY):\n",
    "        print(f'[3/6] Converting IPs to binary... {round(i / len(COLUMNS_TO_IP_BINARY) * 100)}%')\n",
    "        ip_bin = pd.DataFrame(\n",
    "            data=[encoded_ip_to_binary(ip) for ip in localized_alerts.pop(column_name)], \n",
    "            columns=[f'{column_name}{i}' for i in range(40)],\n",
    "            index=localized_alerts.index\n",
    "        )\n",
    "        ip_bin_dfs.append(ip_bin)\n",
    "    print('[3/6] IPs to binary conversion completed.')\n",
    "\n",
    "    port_bin_dfs = []\n",
    "    for i, column_name in enumerate(COLUMNS_TO_PORT_BINARY):\n",
    "        print(f'[4/6] Converting ports to binary... {round(i / len(COLUMNS_TO_PORT_BINARY) * 100)}%')\n",
    "        port_bin = pd.DataFrame(\n",
    "            data=[port_to_binary(ip) for ip in localized_alerts.pop(column_name)], \n",
    "            columns=[f'{column_name}{i}' for i in range(16)],\n",
    "            index=localized_alerts.index\n",
    "        )\n",
    "        port_bin_dfs.append(port_bin)\n",
    "    print('[4/6] Ports to binary conversion completed.')\n",
    "\n",
    "    localized_alerts = pd.concat([localized_alerts] + ip_bin_dfs + port_bin_dfs, axis=1)\n",
    "    del ip_bin, ip_bin_dfs, port_bin, port_bin_dfs\n",
    "    print('[5/6] Dataframe concatenated.')\n",
    "\n",
    "    localized_alerts_by_alert_id = {}\n",
    "    for i, alert_id in enumerate(present_alert_ids):\n",
    "        if i % (len(present_alert_ids) // 20) == 0:\n",
    "            print(f'[6/6] Splitting dataframe by alert ids... {round(i / len(present_alert_ids) * 100)}%')\n",
    "        localized_alerts_part = localized_alerts[localized_alerts['alert_ids'] == alert_id]\n",
    "        if len(localized_alerts_part) == 0:\n",
    "            continue\n",
    "        localized_alerts_part.drop(columns=['alert_ids'], inplace=True)\n",
    "        localized_alerts_by_alert_id[alert_id_to_int(alert_id)] = localized_alerts_part\n",
    "    print('[6/6] Dataframe split by alert ids.')\n",
    "\n",
    "    del localized_alerts\n",
    "\n",
    "    os.makedirs(DUMPS_DIR, exist_ok=True)\n",
    "\n",
    "    with open(LOCALIZED_ALERTS_DUMP_PATH, 'wb') as file:\n",
    "        pickle.dump(\n",
    "            obj=localized_alerts_by_alert_id,\n",
    "            file=file,\n",
    "            protocol=pickle.HIGHEST_PROTOCOL\n",
    "        )\n",
    "        print(f'Processed localized alerts saved at {LOCALIZED_ALERTS_DUMP_PATH}')\n",
    "        \n",
    "next(iter(localized_alerts_by_alert_id.values())).head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:16:09.962693034Z",
     "start_time": "2023-11-17T16:15:53.327728680Z"
    }
   },
   "id": "3a14c3334e74c3ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural net solutions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48112062d27277b4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:16:12.818415918Z",
     "start_time": "2023-11-17T16:16:09.972623643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Device in use: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "class DenseNet(Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = Sequential(\n",
    "            Linear(input_size, 512),\n",
    "            Dropout(.3),\n",
    "            LeakyReLU(.2),\n",
    "\n",
    "            Linear(512, 512 + 256),\n",
    "            Dropout(.3),\n",
    "            LeakyReLU(.2),\n",
    "\n",
    "            Linear(512 + 256, 256+128),\n",
    "            Dropout(.3),\n",
    "            LeakyReLU(.2),\n",
    "\n",
    "            Linear(256+128, 128),\n",
    "            Dropout(.3),\n",
    "            LeakyReLU(.2),\n",
    "\n",
    "            Linear(128, 64),\n",
    "            LeakyReLU(.2),\n",
    "\n",
    "            Linear(64, 16),\n",
    "            LeakyReLU(.2),\n",
    "\n",
    "            Linear(16, 1),\n",
    "            # Sigmoid()\n",
    "        ).type(dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net.forward(x)\n",
    "\n",
    "class_ratio = len(y[y == 1]) / len(y)\n",
    "\n",
    "def loss_fun(y_true: torch.Tensor, y_pred: torch.Tensor) -> Variable:\n",
    "    weights = torch.ones_like(y_true)\n",
    "    weights[y_true == 1] = 1 / class_ratio\n",
    "\n",
    "    return (weights*(y_true - y_pred)**2).mean()\n",
    "\n",
    "def eval_batch(y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "    y_true: np.ndarray = y_true.detach().cpu().numpy()\n",
    "    y_pred: np.ndarray = y_pred.detach().cpu().numpy()\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        acc = accuracy_score(y_true > .5, y_pred > .5)\n",
    "        bac = balanced_accuracy_score(y_true > .5, y_pred > .5)\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            # It might happen, that a batch contains y_true of zeros only.\n",
    "            auc = np.nan\n",
    "    \n",
    "        return acc, bac, auc\n",
    "\n",
    "def fill_nans_with_nearest_val(data: list[float]):\n",
    "    data_np = np.asarray(data)\n",
    "    mask = np.isnan(data_np)\n",
    "    data_np[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), data_np[~mask])\n",
    "    return data_np.tolist()\n",
    "\n",
    "def plot_results(train_score: list[float], test_score: list[float], roll_avg_win_size = 100, title: str = \"Scores on train and test datasets\"):\n",
    "    \n",
    "    train_score = fill_nans_with_nearest_val(train_score)\n",
    "    test_score = fill_nans_with_nearest_val(test_score)\n",
    "    \n",
    "    train_score = pd.Series(train_score).rolling(roll_avg_win_size).mean().tolist() \n",
    "    test_score = pd.Series(test_score).rolling(roll_avg_win_size).mean().tolist()\n",
    "    \n",
    "    plt.plot(np.arange(len(train_score)), train_score, color='r', label='train dataset') \n",
    "    plt.plot(np.arange(len(test_score)), test_score, color='b', label='test dataset') \n",
    "    \n",
    "    plt.xlabel(\"Iteration\") \n",
    "    plt.ylabel(\"Score\") \n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "print('Cuda available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('Device in use:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural net (Dense)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a6d4046c1cc22d"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "NUM_LAYERS = 5\n",
    "\n",
    "EVALUATION_PERIOD = 100\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "X_train = torch.as_tensor(X_train.to_numpy().astype(float))\n",
    "y_train = torch.as_tensor(y_train.to_numpy().astype(float))\n",
    "\n",
    "X_test = torch.as_tensor(X_test.to_numpy().astype(float))\n",
    "y_test = torch.as_tensor(y_test.to_numpy().astype(float))\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        X_train,\n",
    "        y_train\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        X_test, \n",
    "        y_test\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# The \"minus 1\" is because the `alerts_ids` column will be removed.\n",
    "dense_net = DenseNet(input_size=len(X.columns) - 1).to(device=device, dtype=dtype)\n",
    "\n",
    "optim_dense = AdamW(dense_net.parameters(), lr=.0001)\n",
    "\n",
    "def eval_model(dense_net) -> tuple[float, float, float, float]:\n",
    "    \n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dense_net.train(False)\n",
    "    \n",
    "        print('Evaluating:', end=' ')\n",
    "        for n_batch, (X_batch, y_batch) in enumerate(test_data_loader):\n",
    "            y_true_list.append(y_batch)\n",
    "\n",
    "            if n_batch % 10 == 0:\n",
    "                print('*', end='')\n",
    "            torch.cuda.empty_cache()\n",
    "            X_batch = X_batch[:, 1:].to(device=device, dtype=dtype)                    \n",
    "            y_pred = dense_net.forward(X_batch).squeeze()\n",
    "            \n",
    "            y_pred_list.append(y_pred.cpu())\n",
    "    \n",
    "    y_true = torch.cat(y_true_list)\n",
    "    y_pred = torch.cat(y_pred_list)\n",
    "    loss = loss_fun(y_true, y_pred)\n",
    "    acc, bac, auc = eval_batch(y_true, y_pred)\n",
    "        \n",
    "    dense_net.train(True)\n",
    "    \n",
    "    return loss.item(), acc, bac, auc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:51:59.738014251Z",
     "start_time": "2023-11-17T15:51:56.854877436Z"
    }
   },
   "id": "2252de8859629aad"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 0 n_batch: 100 \n",
      ":: loss :: train: 0.517 test:  0.449 \n",
      ":: acc :: train: 0.68 test:  0.842 \n",
      ":: bac :: train: 0.531 test:  0.609 \n",
      ":: auc :: train: 0.542 test:  0.715\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 1 n_batch: 100 \n",
      ":: loss :: train: 0.4 test:  0.383 \n",
      ":: acc :: train: 0.674 test:  0.733 \n",
      ":: bac :: train: 0.679 test:  0.682 \n",
      ":: auc :: train: 0.75 test:  0.777\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 2 n_batch: 100 \n",
      ":: loss :: train: 0.379 test:  0.358 \n",
      ":: acc :: train: 0.635 test:  0.592 \n",
      ":: bac :: train: 0.698 test:  0.692 \n",
      ":: auc :: train: 0.772 test:  0.786\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 3 n_batch: 100 \n",
      ":: loss :: train: 0.36 test:  0.349 \n",
      ":: acc :: train: 0.641 test:  0.617 \n",
      ":: bac :: train: 0.704 test:  0.704 \n",
      ":: auc :: train: 0.788 test:  0.797\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 4 n_batch: 100 \n",
      ":: loss :: train: 0.353 test:  0.35 \n",
      ":: acc :: train: 0.641 test:  0.715 \n",
      ":: bac :: train: 0.713 test:  0.698 \n",
      ":: auc :: train: 0.796 test:  0.806\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 5 n_batch: 100 \n",
      ":: loss :: train: 0.34 test:  0.333 \n",
      ":: acc :: train: 0.657 test:  0.66 \n",
      ":: bac :: train: 0.732 test:  0.716 \n",
      ":: auc :: train: 0.811 test:  0.815\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 6 n_batch: 100 \n",
      ":: loss :: train: 0.344 test:  0.331 \n",
      ":: acc :: train: 0.649 test:  0.693 \n",
      ":: bac :: train: 0.73 test:  0.717 \n",
      ":: auc :: train: 0.815 test:  0.821\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 7 n_batch: 100 \n",
      ":: loss :: train: 0.327 test:  0.329 \n",
      ":: acc :: train: 0.678 test:  0.585 \n",
      ":: bac :: train: 0.739 test:  0.731 \n",
      ":: auc :: train: 0.826 test:  0.827\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 8 n_batch: 100 \n",
      ":: loss :: train: 0.324 test:  0.325 \n",
      ":: acc :: train: 0.674 test:  0.707 \n",
      ":: bac :: train: 0.752 test:  0.74 \n",
      ":: auc :: train: 0.831 test:  0.829\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 9 n_batch: 100 \n",
      ":: loss :: train: 0.322 test:  0.318 \n",
      ":: acc :: train: 0.676 test:  0.638 \n",
      ":: bac :: train: 0.747 test:  0.742 \n",
      ":: auc :: train: 0.833 test:  0.833\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 10 n_batch: 100 \n",
      ":: loss :: train: 0.315 test:  0.314 \n",
      ":: acc :: train: 0.685 test:  0.656 \n",
      ":: bac :: train: 0.759 test:  0.746 \n",
      ":: auc :: train: 0.84 test:  0.836\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 11 n_batch: 100 \n",
      ":: loss :: train: 0.312 test:  0.312 \n",
      ":: acc :: train: 0.684 test:  0.63 \n",
      ":: bac :: train: 0.757 test:  0.75 \n",
      ":: auc :: train: 0.837 test:  0.838\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 12 n_batch: 100 \n",
      ":: loss :: train: 0.311 test:  0.31 \n",
      ":: acc :: train: 0.685 test:  0.677 \n",
      ":: bac :: train: 0.763 test:  0.752 \n",
      ":: auc :: train: 0.846 test:  0.842\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 13 n_batch: 100 \n",
      ":: loss :: train: 0.308 test:  0.306 \n",
      ":: acc :: train: 0.696 test:  0.641 \n",
      ":: bac :: train: 0.77 test:  0.755 \n",
      ":: auc :: train: 0.85 test:  0.844\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 14 n_batch: 100 \n",
      ":: loss :: train: 0.305 test:  0.307 \n",
      ":: acc :: train: 0.693 test:  0.657 \n",
      ":: bac :: train: 0.767 test:  0.75 \n",
      ":: auc :: train: 0.849 test:  0.845\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 15 n_batch: 100 \n",
      ":: loss :: train: 0.299 test:  0.309 \n",
      ":: acc :: train: 0.706 test:  0.713 \n",
      ":: bac :: train: 0.775 test:  0.761 \n",
      ":: auc :: train: 0.856 test:  0.847\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 16 n_batch: 100 \n",
      ":: loss :: train: 0.294 test:  0.304 \n",
      ":: acc :: train: 0.703 test:  0.689 \n",
      ":: bac :: train: 0.776 test:  0.758 \n",
      ":: auc :: train: 0.858 test:  0.848\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 17 n_batch: 100 \n",
      ":: loss :: train: 0.298 test:  0.306 \n",
      ":: acc :: train: 0.697 test:  0.719 \n",
      ":: bac :: train: 0.777 test:  0.763 \n",
      ":: auc :: train: 0.856 test:  0.848\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 18 n_batch: 100 \n",
      ":: loss :: train: 0.294 test:  0.302 \n",
      ":: acc :: train: 0.701 test:  0.694 \n",
      ":: bac :: train: 0.781 test:  0.77 \n",
      ":: auc :: train: 0.86 test:  0.849\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 19 n_batch: 100 \n",
      ":: loss :: train: 0.291 test:  0.312 \n",
      ":: acc :: train: 0.712 test:  0.748 \n",
      ":: bac :: train: 0.779 test:  0.755 \n",
      ":: auc :: train: 0.861 test:  0.848\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 20 n_batch: 100 \n",
      ":: loss :: train: 0.292 test:  0.315 \n",
      ":: acc :: train: 0.697 test:  0.755 \n",
      ":: bac :: train: 0.78 test:  0.762 \n",
      ":: auc :: train: 0.864 test:  0.848\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 21 n_batch: 100 \n",
      ":: loss :: train: 0.288 test:  0.3 \n",
      ":: acc :: train: 0.702 test:  0.684 \n",
      ":: bac :: train: 0.781 test:  0.769 \n",
      ":: auc :: train: 0.865 test:  0.852\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 22 n_batch: 100 \n",
      ":: loss :: train: 0.283 test:  0.301 \n",
      ":: acc :: train: 0.709 test:  0.715 \n",
      ":: bac :: train: 0.785 test:  0.774 \n",
      ":: auc :: train: 0.867 test:  0.853\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 23 n_batch: 100 \n",
      ":: loss :: train: 0.284 test:  0.297 \n",
      ":: acc :: train: 0.716 test:  0.694 \n",
      ":: bac :: train: 0.789 test:  0.766 \n",
      ":: auc :: train: 0.871 test:  0.855\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 24 n_batch: 100 \n",
      ":: loss :: train: 0.28 test:  0.305 \n",
      ":: acc :: train: 0.718 test:  0.746 \n",
      ":: bac :: train: 0.791 test:  0.766 \n",
      ":: auc :: train: 0.872 test:  0.853\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 25 n_batch: 100 \n",
      ":: loss :: train: 0.281 test:  0.307 \n",
      ":: acc :: train: 0.72 test:  0.759 \n",
      ":: bac :: train: 0.791 test:  0.768 \n",
      ":: auc :: train: 0.868 test:  0.854\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 26 n_batch: 100 \n",
      ":: loss :: train: 0.28 test:  0.301 \n",
      ":: acc :: train: 0.715 test:  0.74 \n",
      ":: bac :: train: 0.788 test:  0.771 \n",
      ":: auc :: train: 0.871 test:  0.858\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 27 n_batch: 100 \n",
      ":: loss :: train: 0.274 test:  0.296 \n",
      ":: acc :: train: 0.723 test:  0.715 \n",
      ":: bac :: train: 0.797 test:  0.775 \n",
      ":: auc :: train: 0.875 test:  0.858\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 28 n_batch: 100 \n",
      ":: loss :: train: 0.276 test:  0.303 \n",
      ":: acc :: train: 0.708 test:  0.749 \n",
      ":: bac :: train: 0.793 test:  0.773 \n",
      ":: auc :: train: 0.876 test:  0.857\n",
      "............................................................................................................................\n",
      "Evaluating: ****\n",
      "epoch: 29 n_batch: 100 \n",
      ":: loss :: train: 0.266 test:  0.301 \n",
      ":: acc :: train: 0.731 test:  0.717 \n",
      ":: bac :: train: 0.799 test:  0.77 \n",
      ":: auc :: train: 0.88 test:  0.854\n",
      "........................"
     ]
    }
   ],
   "source": [
    "dense_net.train(True)\n",
    "\n",
    "train_losses = []\n",
    "train_acc_scores = []\n",
    "train_bac_scores = []\n",
    "train_auc_scores = []\n",
    "\n",
    "test_losses = []\n",
    "test_acc_scores = []\n",
    "test_bac_scores = []\n",
    "test_auc_scores = []\n",
    "\n",
    "model_dump_path = DUMPS_DIR + f\"/dense/{datetime.now()}\"\n",
    "os.makedirs(model_dump_path, exist_ok=True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    for n_batch, (X_batch, y_batch) in enumerate(train_data_loader):\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        X_batch = X_batch[:, 1:].to(device=device, dtype=dtype)\n",
    "        y_batch = y_batch.to(device=device, dtype=dtype)\n",
    "        \n",
    "        optim_dense.zero_grad()\n",
    "\n",
    "        y_pred = dense_net.forward(X_batch).squeeze()\n",
    "        del X_batch\n",
    "\n",
    "        loss = loss_fun(y_batch, y_pred)\n",
    "        acc, bac, auc = eval_batch(y_batch, y_pred)\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_acc_scores.append(acc)\n",
    "        train_bac_scores.append(bac)\n",
    "        train_auc_scores.append(auc)\n",
    "                \n",
    "        loss.backward()\n",
    "        optim_dense.step()\n",
    "\n",
    "        # Validate\n",
    "        print('.', end='')\n",
    "        if (n_batch + 1) % EVALUATION_PERIOD == 0:\n",
    "            print('')\n",
    "            loss, acc, bac, auc = eval_model(dense_net)\n",
    "\n",
    "            test_losses.append(loss)\n",
    "            test_acc_scores.append(acc)\n",
    "            test_bac_scores.append(bac)\n",
    "            test_auc_scores.append(auc)\n",
    "    \n",
    "            print(\n",
    "                '\\nepoch:', epoch, 'n_batch:', n_batch + 1,\n",
    "                '\\n:: loss :: train:', round(np.nanmean(train_losses[-EVALUATION_PERIOD:]), 3), \"test: \", round(loss, 3),\n",
    "                '\\n:: acc :: train:', round(np.nanmean(train_acc_scores[-EVALUATION_PERIOD:]), 3), \"test: \", round(acc, 3),\n",
    "                '\\n:: bac :: train:', round(np.nanmean(train_bac_scores[-EVALUATION_PERIOD:]), 3), \"test: \", round(bac, 3),\n",
    "                '\\n:: auc :: train:', round(np.nanmean(train_auc_scores[-EVALUATION_PERIOD:]), 3), \"test: \", round(auc, 3),\n",
    "            )\n",
    "        else:\n",
    "            test_losses.append(np.nan)\n",
    "            test_acc_scores.append(np.nan)\n",
    "            test_bac_scores.append(np.nan)\n",
    "            test_auc_scores.append(np.nan)\n",
    "        \n",
    "    torch.save(dense_net.state_dict(), model_dump_path + f\"/dense_epoch_{epoch}.state\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:53:02.238345445Z",
     "start_time": "2023-11-17T15:51:59.749337024Z"
    }
   },
   "id": "5dbd025346590794"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(train_auc_scores, test_auc_scores, roll_avg_win_size=200, title='AUC cores on train and test datasets')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T15:53:02.451115140Z",
     "start_time": "2023-11-17T15:53:02.239818668Z"
    }
   },
   "id": "16f95f8af3d8991a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural net (LSTM + Dense)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69779c7c9f84773c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 48\n",
    "NUM_LAYERS = 5\n",
    "\n",
    "LSTM_SEQ_TRUNC = 3200\n",
    "LSTM_INPUT_SIZE = len(next(iter(localized_alerts_by_alert_id.values())).columns)\n",
    "LSTM_OUTPUT_SIZE = 120\n",
    "\n",
    "EVALUATION_PERIOD = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "X_train = torch.as_tensor(X_train.to_numpy().astype(float))\n",
    "y_train = torch.as_tensor(y_train.to_numpy().astype(float))\n",
    "\n",
    "X_test = torch.as_tensor(X_test.to_numpy().astype(float))\n",
    "y_test = torch.as_tensor(y_test.to_numpy().astype(float))\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        X_train,\n",
    "        y_train\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_data_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        X_test, \n",
    "        y_test\n",
    "    ),\n",
    "    batch_size=EVAL_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# The \"minus 1\" is because the `alerts_ids` column will be removed.\n",
    "dense_net = DenseNet(input_size=len(X.columns) - 1 + LSTM_OUTPUT_SIZE).to(device=device, dtype=dtype)\n",
    "\n",
    "lstm_net = LSTM(\n",
    "    input_size=LSTM_INPUT_SIZE,\n",
    "    hidden_size=LSTM_OUTPUT_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=0.3,\n",
    "    batch_first=True\n",
    ").to(device=device, dtype=dtype)\n",
    "\n",
    "optim_dense = AdamW(dense_net.parameters(), lr=.00005)\n",
    "optim_lstm = AdamW(lstm_net.parameters(), lr=.00005)\n",
    "\n",
    "class_ratio = len(y[y == 1]) / len(y)\n",
    "\n",
    "def loss_fun(y_true: torch.Tensor, y_pred: torch.Tensor) -> Variable:\n",
    "    weight = torch.ones_like(y_true)\n",
    "    weight[y_true == 1] = 1 / class_ratio\n",
    "\n",
    "    weighted_squares = weight * (y_true - y_pred) ** 2\n",
    "    return weighted_squares.mean()\n",
    "\n",
    "def get_batch_localized_alerts(X: torch.Tensor) -> torch.Tensor:\n",
    "    alert_ids = X[:, 0]\n",
    "\n",
    "    localized_alerts = []\n",
    "    for alert_id in alert_ids:\n",
    "        alert_id = int(alert_id.item())\n",
    "        if alert_id not in localized_alerts_by_alert_id:\n",
    "            localized_alerts.append(torch.zeros(size=(LSTM_INPUT_SIZE, ), dtype=dtype, device=device))\n",
    "            continue\n",
    "\n",
    "        localized_alerts_np = localized_alerts_by_alert_id[alert_id].to_numpy()\n",
    "        if len(localized_alerts_np) > LSTM_SEQ_TRUNC:\n",
    "            localized_alerts_np = localized_alerts_np[-LSTM_SEQ_TRUNC:, :]\n",
    "\n",
    "        localized_alerts.append(torch.as_tensor(localized_alerts_np.astype(float), dtype=dtype, device=device))\n",
    "    \n",
    "    return pad_sequence(localized_alerts, batch_first=True)\n",
    "\n",
    "def forward_lstm_dense(X_data: torch.Tensor):           \n",
    "    batch_localized_alerts = get_batch_localized_alerts(X_data)\n",
    "    X_data = X_data[:, 1:]\n",
    "    \n",
    "    lstm_all_outs, _ = lstm_net.forward(batch_localized_alerts)\n",
    "    lstm_out = lstm_all_outs[:, -1, :]\n",
    "\n",
    "    y_pred = dense_net.forward(torch.cat([X_data, lstm_out], dim=1))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def eval_model(dense_net, lstm_net) -> tuple[float, float, float, float]:\n",
    "    \n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        lstm_net.train(False)\n",
    "        dense_net.train(False)\n",
    "        print('Evaluating:', end=' ')\n",
    "        for n_batch, (X_batch, y_batch) in enumerate(test_data_loader):\n",
    "            y_true_list.append(y_batch)\n",
    "            if n_batch % 10 == 0:\n",
    "                print('*', end='')\n",
    "            torch.cuda.empty_cache()\n",
    "            X_batch = X_batch.to(device=device, dtype=dtype)\n",
    "            \n",
    "            y_pred = forward_lstm_dense(X_batch)\n",
    "            \n",
    "            y_pred_list.append(y_pred.cpu())\n",
    "        \n",
    "    y_true = torch.cat(y_true_list)\n",
    "    y_pred = torch.cat(y_pred_list)\n",
    "    loss = loss_fun(y_true, y_pred)\n",
    "    acc, bac, auc = eval_batch(y_true, y_pred)\n",
    "    \n",
    "    lstm_net.train(True)\n",
    "    dense_net.train(True)\n",
    "\n",
    "    return loss.item(), acc, bac, auc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T16:17:51.733018083Z",
     "start_time": "2023-11-17T16:17:50.473586069Z"
    }
   },
   "id": "7cdcfc5ad226bea7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 0 n_batch: 1000 \n",
      ":: loss :: train: 0.541 test:  0.493 \n",
      ":: acc :: train: 0.568 test:  0.253 \n",
      ":: bac :: train: 0.501 test:  0.507 \n",
      ":: auc :: train: 0.478 test:  0.514\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 1 n_batch: 1000 \n",
      ":: loss :: train: 0.504 test:  0.488 \n",
      ":: acc :: train: 0.54 test:  0.572 \n",
      ":: bac :: train: 0.518 test:  0.566 \n",
      ":: auc :: train: 0.525 test:  0.592\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 2 n_batch: 1000 \n",
      ":: loss :: train: 0.495 test:  0.487 \n",
      ":: acc :: train: 0.547 test:  0.146 \n",
      ":: bac :: train: 0.537 test:  0.505 \n",
      ":: auc :: train: 0.553 test:  0.594\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 3 n_batch: 1000 \n",
      ":: loss :: train: 0.497 test:  0.49 \n",
      ":: acc :: train: 0.51 test:  0.866 \n",
      ":: bac :: train: 0.524 test:  0.549 \n",
      ":: auc :: train: 0.552 test:  0.62\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 4 n_batch: 1000 \n",
      ":: loss :: train: 0.499 test:  0.486 \n",
      ":: acc :: train: 0.511 test:  0.138 \n",
      ":: bac :: train: 0.523 test:  0.511 \n",
      ":: auc :: train: 0.555 test:  0.648\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 5 n_batch: 1000 \n",
      ":: loss :: train: 0.497 test:  0.486 \n",
      ":: acc :: train: 0.504 test:  0.59 \n",
      ":: bac :: train: 0.519 test:  0.628 \n",
      ":: auc :: train: 0.551 test:  0.674\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 6 n_batch: 1000 \n",
      ":: loss :: train: 0.495 test:  0.495 \n",
      ":: acc :: train: 0.512 test:  0.941 \n",
      ":: bac :: train: 0.527 test:  0.507 \n",
      ":: auc :: train: 0.576 test:  0.681\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 7 n_batch: 1000 \n",
      ":: loss :: train: 0.493 test:  0.509 \n",
      ":: acc :: train: 0.524 test:  0.942 \n",
      ":: bac :: train: 0.541 test:  0.5 \n",
      ":: auc :: train: 0.58 test:  0.71\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 8 n_batch: 1000 \n",
      ":: loss :: train: 0.495 test:  0.491 \n",
      ":: acc :: train: 0.519 test:  0.925 \n",
      ":: bac :: train: 0.538 test:  0.542 \n",
      ":: auc :: train: 0.583 test:  0.701\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 9 n_batch: 1000 \n",
      ":: loss :: train: 0.497 test:  0.487 \n",
      ":: acc :: train: 0.495 test:  0.767 \n",
      ":: bac :: train: 0.528 test:  0.662 \n",
      ":: auc :: train: 0.581 test:  0.713\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 10 n_batch: 1000 \n",
      ":: loss :: train: 0.496 test:  0.488 \n",
      ":: acc :: train: 0.501 test:  0.883 \n",
      ":: bac :: train: 0.532 test:  0.579 \n",
      ":: auc :: train: 0.583 test:  0.662\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 11 n_batch: 1000 \n",
      ":: loss :: train: 0.493 test:  0.488 \n",
      ":: acc :: train: 0.5 test:  0.821 \n",
      ":: bac :: train: 0.527 test:  0.677 \n",
      ":: auc :: train: 0.593 test:  0.752\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 12 n_batch: 1000 \n",
      ":: loss :: train: 0.495 test:  0.499 \n",
      ":: acc :: train: 0.484 test:  0.942 \n",
      ":: bac :: train: 0.532 test:  0.5 \n",
      ":: auc :: train: 0.6 test:  0.711\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 13 n_batch: 1000 \n",
      ":: loss :: train: 0.491 test:  0.488 \n",
      ":: acc :: train: 0.5 test:  0.835 \n",
      ":: bac :: train: 0.552 test:  0.657 \n",
      ":: auc :: train: 0.624 test:  0.757\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 14 n_batch: 1000 \n",
      ":: loss :: train: 0.494 test:  0.486 \n",
      ":: acc :: train: 0.477 test:  0.359 \n",
      ":: bac :: train: 0.53 test:  0.604 \n",
      ":: auc :: train: 0.601 test:  0.712\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 15 n_batch: 1000 \n",
      ":: loss :: train: 0.496 test:  0.486 \n",
      ":: acc :: train: 0.483 test:  0.717 \n",
      ":: bac :: train: 0.533 test:  0.68 \n",
      ":: auc :: train: 0.612 test:  0.735\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 16 n_batch: 1000 \n",
      ":: loss :: train: 0.497 test:  0.496 \n",
      ":: acc :: train: 0.455 test:  0.942 \n",
      ":: bac :: train: 0.528 test:  0.5 \n",
      ":: auc :: train: 0.6 test:  0.749\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 17 n_batch: 1000 \n",
      ":: loss :: train: 0.498 test:  0.495 \n",
      ":: acc :: train: 0.452 test:  0.941 \n",
      ":: bac :: train: 0.527 test:  0.504 \n",
      ":: auc :: train: 0.605 test:  0.762\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 18 n_batch: 1000 \n",
      ":: loss :: train: 0.491 test:  0.521 \n",
      ":: acc :: train: 0.498 test:  0.942 \n",
      ":: bac :: train: 0.533 test:  0.5 \n",
      ":: auc :: train: 0.604 test:  0.763\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 19 n_batch: 1000 \n",
      ":: loss :: train: 0.49 test:  0.487 \n",
      ":: acc :: train: 0.496 test:  0.76 \n",
      ":: bac :: train: 0.535 test:  0.685 \n",
      ":: auc :: train: 0.608 test:  0.745\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 20 n_batch: 1000 \n",
      ":: loss :: train: 0.499 test:  0.511 \n",
      ":: acc :: train: 0.429 test:  0.942 \n",
      ":: bac :: train: 0.526 test:  0.5 \n",
      ":: auc :: train: 0.615 test:  0.794\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 21 n_batch: 1000 \n",
      ":: loss :: train: 0.487 test:  0.516 \n",
      ":: acc :: train: 0.524 test:  0.942 \n",
      ":: bac :: train: 0.546 test:  0.5 \n",
      ":: auc :: train: 0.617 test:  0.768\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 22 n_batch: 1000 \n",
      ":: loss :: train: 0.492 test:  0.496 \n",
      ":: acc :: train: 0.482 test:  0.942 \n",
      ":: bac :: train: 0.527 test:  0.502 \n",
      ":: auc :: train: 0.62 test:  0.777\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 23 n_batch: 1000 \n",
      ":: loss :: train: 0.486 test:  0.487 \n",
      ":: acc :: train: 0.535 test:  0.823 \n",
      ":: bac :: train: 0.56 test:  0.686 \n",
      ":: auc :: train: 0.646 test:  0.778\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 24 n_batch: 1000 \n",
      ":: loss :: train: 0.494 test:  0.49 \n",
      ":: acc :: train: 0.466 test:  0.926 \n",
      ":: bac :: train: 0.523 test:  0.578 \n",
      ":: auc :: train: 0.613 test:  0.787\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 25 n_batch: 1000 \n",
      ":: loss :: train: 0.49 test:  0.497 \n",
      ":: acc :: train: 0.51 test:  0.942 \n",
      ":: bac :: train: 0.553 test:  0.501 \n",
      ":: auc :: train: 0.627 test:  0.775\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 26 n_batch: 1000 \n",
      ":: loss :: train: 0.497 test:  0.488 \n",
      ":: acc :: train: 0.471 test:  0.917 \n",
      ":: bac :: train: 0.534 test:  0.597 \n",
      ":: auc :: train: 0.613 test:  0.759\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 27 n_batch: 1000 \n",
      ":: loss :: train: 0.492 test:  0.487 \n",
      ":: acc :: train: 0.475 test:  0.875 \n",
      ":: bac :: train: 0.529 test:  0.663 \n",
      ":: auc :: train: 0.634 test:  0.774\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 28 n_batch: 1000 \n",
      ":: loss :: train: 0.493 test:  0.485 \n",
      ":: acc :: train: 0.485 test:  0.342 \n",
      ":: bac :: train: 0.535 test:  0.621 \n",
      ":: auc :: train: 0.62 test:  0.772\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 29 n_batch: 1000 \n",
      ":: loss :: train: 0.492 test:  0.489 \n",
      ":: acc :: train: 0.475 test:  0.936 \n",
      ":: bac :: train: 0.538 test:  0.538 \n",
      ":: auc :: train: 0.639 test:  0.771\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 30 n_batch: 1000 \n",
      ":: loss :: train: 0.494 test:  0.489 \n",
      ":: acc :: train: 0.433 test:  0.917 \n",
      ":: bac :: train: 0.532 test:  0.576 \n",
      ":: auc :: train: 0.638 test:  0.75\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 31 n_batch: 1000 \n",
      ":: loss :: train: 0.489 test:  0.49 \n",
      ":: acc :: train: 0.528 test:  0.939 \n",
      ":: bac :: train: 0.554 test:  0.537 \n",
      ":: auc :: train: 0.636 test:  0.787\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 32 n_batch: 1000 \n",
      ":: loss :: train: 0.49 test:  0.492 \n",
      ":: acc :: train: 0.47 test:  0.941 \n",
      ":: bac :: train: 0.544 test:  0.504 \n",
      ":: auc :: train: 0.644 test:  0.767\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 33 n_batch: 1000 \n",
      ":: loss :: train: 0.489 test:  0.495 \n",
      ":: acc :: train: 0.486 test:  0.942 \n",
      ":: bac :: train: 0.539 test:  0.5 \n",
      ":: auc :: train: 0.636 test:  0.757\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 34 n_batch: 1000 \n",
      ":: loss :: train: 0.485 test:  0.494 \n",
      ":: acc :: train: 0.505 test:  0.942 \n",
      ":: bac :: train: 0.545 test:  0.502 \n",
      ":: auc :: train: 0.648 test:  0.777\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 35 n_batch: 1000 \n",
      ":: loss :: train: 0.486 test:  0.487 \n",
      ":: acc :: train: 0.508 test:  0.845 \n",
      ":: bac :: train: 0.558 test:  0.707 \n",
      ":: auc :: train: 0.65 test:  0.808\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 36 n_batch: 1000 \n",
      ":: loss :: train: 0.489 test:  0.513 \n",
      ":: acc :: train: 0.469 test:  0.942 \n",
      ":: bac :: train: 0.54 test:  0.5 \n",
      ":: auc :: train: 0.648 test:  0.807\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 37 n_batch: 1000 \n",
      ":: loss :: train: 0.493 test:  0.485 \n",
      ":: acc :: train: 0.458 test:  0.109 \n",
      ":: bac :: train: 0.529 test:  0.52 \n",
      ":: auc :: train: 0.644 test:  0.777\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 38 n_batch: 1000 \n",
      ":: loss :: train: 0.491 test:  0.487 \n",
      ":: acc :: train: 0.453 test:  0.841 \n",
      ":: bac :: train: 0.53 test:  0.702 \n",
      ":: auc :: train: 0.636 test:  0.798\n",
      "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Evaluating: *****************\n",
      "epoch: 39 n_batch: 1000 \n",
      ":: loss :: train: 0.485 test:  0.491 \n",
      ":: acc :: train: 0.523 test:  0.939 \n",
      ":: bac :: train: 0.563 test:  0.524 \n",
      ":: auc :: train: 0.656 test:  0.778\n",
      "..........................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "lstm_net.train(True)\n",
    "dense_net.train(True)\n",
    "\n",
    "train_losses = []\n",
    "train_acc_scores = []\n",
    "train_bac_scores = []\n",
    "train_auc_scores = []\n",
    "\n",
    "test_losses = []\n",
    "test_acc_scores = []\n",
    "test_bac_scores = []\n",
    "test_auc_scores = []\n",
    "\n",
    "model_dump_path = DUMPS_DIR + f\"/lstm_dense/{datetime.now()} \"\n",
    "os.makedirs(model_dump_path, exist_ok=True)\n",
    "        \n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    for n_batch, (X_batch, y_batch) in enumerate(train_data_loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        X_batch = X_batch.to(device=device, dtype=dtype)\n",
    "        y_batch = y_batch.to(device=device, dtype=dtype)\n",
    "        \n",
    "        optim_dense.zero_grad()\n",
    "        optim_lstm.zero_grad()\n",
    "\n",
    "        y_pred = forward_lstm_dense(X_batch)\n",
    "\n",
    "        loss = loss_fun(y_batch, y_pred)\n",
    "        acc, bac, auc = eval_batch(y_batch, y_pred)\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_acc_scores.append(acc)\n",
    "        train_bac_scores.append(bac)\n",
    "        train_auc_scores.append(auc)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim_dense.step()\n",
    "        optim_lstm.step()\n",
    "\n",
    "        # Validate\n",
    "        print('.', end='')\n",
    "        if (n_batch + 1) % EVALUATION_PERIOD == 0:\n",
    "            print('')\n",
    "            loss, acc, bac, auc = eval_model(dense_net, lstm_net)\n",
    "\n",
    "            test_losses.append(loss)\n",
    "            test_acc_scores.append(acc)\n",
    "            test_bac_scores.append(bac)\n",
    "            test_auc_scores.append(auc)\n",
    "    \n",
    "            print(\n",
    "                '\\nepoch:', epoch, 'n_batch:', n_batch + 1,\n",
    "                '\\n:: loss :: train:', round(np.nanmean(train_losses[-EVALUATION_PERIOD:]), 3), \"test: \", round(loss, 3),\n",
    "                '\\n:: acc :: train:', round(np.nanmean(train_acc_scores[-EVALUATION_PERIOD:]), 3), \"test: \", round(acc, 3),\n",
    "                '\\n:: bac :: train:', round(np.nanmean(train_bac_scores[-EVALUATION_PERIOD:]), 3), \"test: \", round(bac, 3),\n",
    "                '\\n:: auc :: train:', round(np.nanmean(train_auc_scores[-EVALUATION_PERIOD:]), 3), \"test: \", round(auc, 3),\n",
    "            )\n",
    "        else:\n",
    "            test_losses.append(np.nan)\n",
    "            test_acc_scores.append(np.nan)\n",
    "            test_bac_scores.append(np.nan)\n",
    "            test_auc_scores.append(np.nan)\n",
    "    \n",
    "    torch.save(dense_net.state_dict(), model_dump_path + f\"/dense_epoch_{epoch}.state\")\n",
    "    torch.save(lstm_net.state_dict(), model_dump_path + f\"/lstm_epoch_{epoch}.state\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:52:43.497358071Z",
     "start_time": "2023-11-17T16:17:52.074803316Z"
    }
   },
   "id": "bef2c07e896fd342"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(train_auc_scores, test_auc_scores, roll_avg_win_size=2000, title='AUC cores on train and test datasets')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:55:50.178620815Z",
     "start_time": "2023-11-17T18:55:49.851901461Z"
    }
   },
   "id": "1c980c62204c1615"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest and statistical analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fcf535937611799"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "LOCALIZED_ALERTS_RF_DUMP_PATH = f'{DUMPS_DIR}/localized_alerts_rf_data_dump.pkl'\n",
    "\n",
    "if os.path.exists(LOCALIZED_ALERTS_RF_DUMP_PATH):\n",
    "    print(f'Processed localized alerts stats vectors found at {LOCALIZED_ALERTS_RF_DUMP_PATH}. Loading dump.')\n",
    "    with open(LOCALIZED_ALERTS_RF_DUMP_PATH, 'rb') as handle:\n",
    "        localized_alerts_by_alert_id = pickle.load(handle)\n",
    "        \n",
    "else:\n",
    "    print(f'Processed localized alerts stats vectors dump not found. Preprocessing data...')\n",
    "    def transform_to_stats_vectors():\n",
    "        result = {}\n",
    "        for i, (alert_id, localized_alerts) in enumerate(localized_alerts_by_alert_id.items()):\n",
    "            \n",
    "            n_alert_ids = len(localized_alerts_by_alert_id)\n",
    "            \n",
    "            if i % (n_alert_ids // 20) == 0:\n",
    "                print(f\"`localized_alerts` data transformation... {round(i / len(localized_alerts_by_alert_id) * 100)}%\")\n",
    "            \n",
    "            stats_vector = []\n",
    "            for column_name in localized_alerts.columns:\n",
    "                column_np: np.ndarray = localized_alerts[column_name].to_numpy().astype(float)\n",
    "                \n",
    "                stats_vector.append(column_np.mean())\n",
    "                stats_vector.append(column_np.min())\n",
    "                stats_vector.append(column_np.max())\n",
    "                stats_vector.append(column_np.std())\n",
    "                \n",
    "                del column_np\n",
    "    \n",
    "            result[alert_id] = np.asarray(stats_vector, dtype=np.float16)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    localized_alerts_stats_vectors = transform_to_stats_vectors()\n",
    "    print(\"`localized_alerts` data transformed.\")\n",
    "    \n",
    "    os.makedirs(DUMPS_DIR, exist_ok=True)\n",
    "    \n",
    "    with open(LOCALIZED_ALERTS_RF_DUMP_PATH, 'wb') as file:\n",
    "        pickle.dump(\n",
    "            obj=localized_alerts_stats_vectors,\n",
    "            file=file,\n",
    "            protocol=pickle.HIGHEST_PROTOCOL\n",
    "        )\n",
    "        print(f'Processed localized alerts stats vectors saved at {LOCALIZED_ALERTS_RF_DUMP_PATH}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aef815998a40627"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_batch_localized_alerts(X: torch.Tensor) -> np.ndarray:\n",
    "    alert_ids = X[:, 0]\n",
    "\n",
    "    localized_alerts = []\n",
    "    for i, alert_id in enumerate(alert_ids):\n",
    "        alert_id = alert_id_to_int(alert_id)\n",
    "        if alert_id not in localized_alerts_by_alert_id:\n",
    "            localized_alerts.append(np.zeros(shape=(LSTM_INPUT_SIZE, )))\n",
    "            continue\n",
    "\n",
    "        localized_alerts.append(localized_alerts_stats_vectors[alert_id])\n",
    "    return np.concatenate(localized_alerts)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "print(\"Base data split.\")\n",
    "\n",
    "X_train = np.concatenate([X_train.to_numpy()[:, 1:], get_batch_localized_alerts(X_train.to_numpy())], axis=1)\n",
    "X_test = np.concatenate([X_test.to_numpy()[:, 1:], get_batch_localized_alerts(X_train.to_numpy())], axis=1)\n",
    "print(\"Data concatenated.\")\n",
    "\n",
    "random_forest = RandomForestClassifier(class_weight={0: class_ratio, 1:1})\n",
    "y_pred = random_forest.fit_transform(X_train)\n",
    "print(\"Random forest fitting completed.\")\n",
    "\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print(f\"Train dataset auc score: {auc}\")\n",
    "\n",
    "y_pred = random_forest.transform(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"Test dataset auc score: {auc}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42cb3199dc0925e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate final result on test dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "801148749d7cc053"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   alert_ids  timestamp_dist  start_hour  start_minute  start_second  \\\n0      16069        0.000000          11            44            26   \n1      12466        0.000000          22            39            30   \n2      44826        0.000000           7            57             5   \n3      48988        0.000000           0            21            33   \n4      49868       17.978543          18            39            29   \n\n   correlatedcount  srcip_cd  dstip_cd  srcport_cd  dstport_cd  ...  p8w$2.0  \\\n0         1.000000       1.0       1.0    1.000000         1.0  ...    False   \n1         1.000000       1.0       1.0    1.000000         1.0  ...    False   \n2         1.000000       1.0       1.0    1.000000         1.0  ...    False   \n3         1.000000       1.0       1.0    1.000000         1.0  ...    False   \n4         3.906891       1.0       1.0    3.906891         1.0  ...    False   \n\n   p8w$3.0  p8w$4.0  p8w$5.0  p8w$nan  p8d$1.0  p8d$2.0  p8d$3.0  p8d$4.0  \\\n0    False    False    False    False     True    False    False    False   \n1    False    False    False    False     True    False    False    False   \n2    False    False    False    False     True    False    False    False   \n3    False    False    False    False     True    False    False    False   \n4    False    False    False    False     True    False    False    False   \n\n   p8d$nan  \n0    False  \n1    False  \n2    False  \n3    False  \n4    False  \n\n[5 rows x 380 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alert_ids</th>\n      <th>timestamp_dist</th>\n      <th>start_hour</th>\n      <th>start_minute</th>\n      <th>start_second</th>\n      <th>correlatedcount</th>\n      <th>srcip_cd</th>\n      <th>dstip_cd</th>\n      <th>srcport_cd</th>\n      <th>dstport_cd</th>\n      <th>...</th>\n      <th>p8w$2.0</th>\n      <th>p8w$3.0</th>\n      <th>p8w$4.0</th>\n      <th>p8w$5.0</th>\n      <th>p8w$nan</th>\n      <th>p8d$1.0</th>\n      <th>p8d$2.0</th>\n      <th>p8d$3.0</th>\n      <th>p8d$4.0</th>\n      <th>p8d$nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16069</td>\n      <td>0.000000</td>\n      <td>11</td>\n      <td>44</td>\n      <td>26</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12466</td>\n      <td>0.000000</td>\n      <td>22</td>\n      <td>39</td>\n      <td>30</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44826</td>\n      <td>0.000000</td>\n      <td>7</td>\n      <td>57</td>\n      <td>5</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48988</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>21</td>\n      <td>33</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49868</td>\n      <td>17.978543</td>\n      <td>18</td>\n      <td>39</td>\n      <td>29</td>\n      <td>3.906891</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.906891</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 380 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unknown = cybersecurity_test = pd.read_csv('data/cybersecurity_test.csv', sep='|')\n",
    "X_unknown.pop('client_code')\n",
    "\n",
    "# Encode alert_ids to int (str values are invalid in torch tensors)\n",
    "X_unknown['alert_ids'] = X_unknown['alert_ids'].apply(alert_id_to_int)\n",
    "\n",
    "# Transform IPs into binary\n",
    "X_ip_bin = pd.DataFrame(\n",
    "    data=[encoded_ip_to_binary(ip) for ip in X_unknown.pop('ip')],\n",
    "    columns=[f'ip{i}' for i in range(40)],\n",
    "    index=X_unknown.index\n",
    ")\n",
    "X_unknown = pd.concat([X_unknown, X_ip_bin], axis=1)\n",
    "\n",
    "# Logarithmize columns\n",
    "for column_name in COLUMNS_TO_LOGARITHMIZE:\n",
    "    X_unknown[column_name] = X_unknown[column_name].apply(logarithimize)\n",
    "\n",
    "# Encode columns to one-hot\n",
    "X_unknown = pd.get_dummies(X_unknown, columns=COLUMNS_TO_ONEHOTIZE, prefix_sep='$', dummy_na=True, dtype=bool)\n",
    "\n",
    "# Drop columns absent in training data.\n",
    "X_unknown.drop(columns=[col for col in X_unknown.columns if col not in X.columns], inplace=True)\n",
    "\n",
    "# Fill one-hot columns that are missing in the `X_unknown` dataset.\n",
    "for i, X_train_column in enumerate(X.columns):\n",
    "    if len(X_unknown.columns) > i and list(X_unknown.columns)[i] == X_train_column:\n",
    "        continue\n",
    "    else:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\") # Inefficient, but we'll manage calling this a few times.\n",
    "            X_unknown.insert(i, X_train_column, [0]*len(X_unknown))\n",
    "\n",
    "X_unknown.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:56:18.013611222Z",
     "start_time": "2023-11-17T18:56:06.972790074Z"
    }
   },
   "id": "e6692197698bfc8f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.5573563575744629],\n [0.5034943222999573],\n [0.6352086663246155],\n [0.5542920827865601],\n [0.6098483204841614],\n [0.6344156861305237],\n [0.5939103364944458],\n [0.6026078462600708],\n [0.6200844645500183],\n [0.6026825904846191]]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The \"minus 1\" is because the `alerts_ids` column will be removed.\n",
    "dense_net = DenseNet(input_size=len(X_unknown.columns) - 1 + LSTM_OUTPUT_SIZE).to(dtype=dtype, device=device)\n",
    "\n",
    "lstm_net = LSTM(\n",
    "    input_size=LSTM_INPUT_SIZE,\n",
    "    hidden_size=LSTM_OUTPUT_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=0.3,\n",
    "    batch_first=True\n",
    ").to(dtype=dtype, device=device)\n",
    "\n",
    "dense_net.load_state_dict(torch.load(model_dump_path + f\"/dense_epoch_{EPOCHS - 1}.state\"))\n",
    "lstm_net.load_state_dict(torch.load(model_dump_path + f\"/lstm_epoch_{EPOCHS - 1}.state\"))\n",
    "\n",
    "y_results = []\n",
    "for i in range(0, len(X_unknown), 8):\n",
    "    X_batch = X_unknown.iloc[i:i+8, :]\n",
    "    y_batch = forward_lstm_dense(torch.as_tensor(X_batch.to_numpy().astype(float), dtype=dtype, device=device))\n",
    "    y_results.extend(y_batch.tolist())\n",
    "\n",
    "y_results[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:57:07.384136130Z",
     "start_time": "2023-11-17T18:56:18.017652565Z"
    }
   },
   "id": "8d4af4d8df23d7af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "337e8d42610a8ae9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
